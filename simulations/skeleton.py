"""
This is a suggestion for structuring your simulation code properly.
However, it is not set in stone. You may modify it if you feel like
you have a good reason to do so.
"""

from typing import Callable, Tuple
import numpy as np
from numpy import ndarray, random as rnd
from numba import njit


# Global constants

SIGMA               = 3.405e-10
CONSTANT_BOLTZMAN   = 1.38064852e-23
ETA_OVER_BOLTZMAN   = 119.8
ETA = ETA_OVER_BOLTZMAN * CONSTANT_BOLTZMAN
M = 6.6335209e-26

"""
Functions to initialise the system
"""

def init_rv_uniform(dimentions: int,
                    num_particles: int, L: float) -> [np.ndarray, np.ndarray]:
    """
    Function intended to construct two 2D matrices with all elements
    randomly generated and considered to be the initial conditions for
    the particles.

    The elements of both matrices are continuous uniform distributed.
    When generating the initial condition of the position, it is assumed
    that the box is in the first quadrand/octant. The elements of ini_pos
    are in the domain [0,1].
    The elements of init_vel are in the domain [-1,1].

    Parameters
    ----------
    dimentions : int
        value for the number of spacial dimentions the particles exist in
    num_particles: int
        value for the number of particles
    L : int
        size of the box, should scale with the number of particles

    Return
    ------
    init_pos : np.ndarray
        2D matrice for the intial position vectors
    init_vel : np.ndarray
        2D matrice for the intial velocity vectors
    """

    init_pos = L * np.random.random_sample(size=(num_particles, dimentions))
    init_vel = (np.random.random_sample(size=(num_particles, dimentions))
                - 0.5) * 2

    return init_pos, init_vel


def gen_rv_matrices(dimentions: int, num_particles: int,
                    num_time_steps: int) -> [np.ndarray, np.ndarray]:
    """
    This function constructs two 3D matrices with with all elements
    contianing the value 0 intened to be used to store the position and
    velocity vectors of the particles at different times.

    Parameters
    ----------
    dimentions : int
        value for the number of spacial dimentions the particles exist in
    num_particles : int
        value for the number of particles
    num_time_steps : int
        value for the number of time steps

    Returns
    -------
    position : np.ndarray
        the 3D matrice for the position vectors
    velocity : np.ndarray
        the 3D matrice for the velocity vectors
    """

    position = np.zeros((num_time_steps, num_particles, dimentions),
                        dtype=float)
    velocity = np.zeros((num_time_steps, num_particles, dimentions),
                        dtype=float)

    return position, velocity


def store_rv(all_pos: np.ndarray, all_vel: np.ndarray,
             current_pos: np.ndarray, current_vel: np.ndarray,
             time_step: int) -> [np.ndarray, np.ndarray]:
    """
    Funtion to store the calculated positions and velocities of the
    particles at different time steps.

    all_pos and all_vel should either be generated by gen_rv_matrices or
    be a previous output of store_rv.

    Parameters
    ----------
    time_step : int
        the number of the time step corresponding to the time step of the
        calculated positions and velocities
    all_pos : np.ndarray
        3D matrice containing all the previously calculated positions of
        the particles (i.e. current_pos for lower time_step)
    all_vel : np.ndarray
        3D matrice containing all the previously calculated velocities of
        the particles (i.e. current_vel for lower time_step)
    current_pos : np.ndarray
        2D matrice containing the calculated position vectors of the
        particles at time_step
    current_vel : np.ndarray
        2D matrice containing the calculated velocity vectors of the
        particles at time_step

    Returns
    -------
    all_pos : np.ndarray
        Altered 3D matrice used to store the position vectors now including
        current_pos at time_step
    all_vel : np.ndarray
        Altered 3D matrice used to store the velocity vectors now including
        current_vel at time_step
    """

    all_pos[time_step, :, :] = current_pos
    all_vel[time_step, :, :] = current_vel

    return all_pos, all_vel

def init_v_gauss(num_particles: int, temperature: float, dimensions = 3):
    """Function to generate the initial velocities for N particles in
    three spacial dimensions at a fixed temperature.

    Parameters
    ----------
    num_particles : int
        Number of particles in the system
    temperature : float
        Temperature of the system [K]
    dimensions: int
        Number of spacial dimensions the particle can move through

    Return
    ------
    init_v : np.ndarray
        The initial velocity vectors (stationary center of mass)
            Interpretation:
            Element (i,j) represents the velocity of particle i in dimension j
    """

    #Converting the temperature into dimensionless variable
    T_dim = temperature/ETA_OVER_BOLTZMAN

    #The mean and standard deviation of the Baussian distribution
    mean = 0
    std = np.sqrt(T_dim)

    #Generating initial velocities
    init_velocity = rnd.normal(mean, std, size = (num_particles, dimensions))

    #Adjusting the initial velocities to create a stationary center of mass
    Net_velocity = np.sum(init_velocity, axis=0)
    init_v = init_velocity - Net_velocity[np.newaxis,:]/num_particles

    return init_v


def MB_distribution(velocity: np.ndarray, temperature: float):
    """Function to calculate the Maxwell-Boltzmann distribution using
    dimensionless variables

    Parameters
    ----------
    velocity : np.ndarray
        velocity of a particle [dimensionless]
    temperature : float
        temperature of the system [K]

    Returns
    -------
    MB_dist : np.ndarray
        Maxwell-Boltzmann probability distribution at different velocities
    """

    #Dimentionless temperature
    T_dim = temperature/ETA_OVER_BOLTZMAN

    MB_dist = 4* np.pi* (2* np.pi* T_dim)**(-3/2) * velocity**2 * np.exp(-velocity** 2/ (2* T_dim))

    return MB_dist

def cell_dim(num_par: int, phase = '', temp = 273.15) -> float:
    """Function to determine the size of the cell and the length of the lattice
    vectors for different phases based on the particle density from literature.

    Parameters
    ----------
    temp: float
        temperature of the system [K]
    num_par: int
        number of particles in the cell
    phase: str
        The phase of the system.
        Input can either be s (solid), l (liquid), g (gas)

    Return
    ------
    L: float
        Size of the cell according to the literature
    alpha: float
        Lenght of the lattice vectors

    Notes
    -----
    Properties of argon at different phases according to literature.
    Molar mass of argon: 40 g/mol
    T: temperature, P: pressure, rho: density, n: particle density, n': dimensionless n

     phase || T [K]  | P [bar] | rho [g/L] | n [m^-3] | n' [-]
    -------||--------|---------|-----------|----------|----------
     Ag(s) || 83.81  | 1       | 1650      | 2.484e28 | 0.981
     Ag(l) || 87.302 | 1       | 1398.3    | 2.105e28 | 0.831
     Ar(g) || 273.15 | 1       | 1.664     | 2.505e25 | 9.889e-4

    The volume is determined based on the particle density from literature. It is assumed
    that the particle density does not change at different conditions for both the solid
    and gas phase. The particle density is epected to change at different conditions for
    the gas phase. An ideal gas model is assumed for the gas phase,
                            PV = NkT ------> n = N/V = P/(kT)
    Therefore the particle density n(T) at temperature T is calculated from the particle
    density from literature n(T_0) at the temperature from literature T_0.
                                n(T) = n(T_0) * T_0 / T

    !!!-------------------------------------------------------------------------------!!!
    The calculations are performed in dimensionless units and the output values are
    calculated in dimensionless units
    !!!-------------------------------------------------------------------------------!!!
    """

    "constants"
    T_dim = 119.8
    n_sol = 0.981
    n_liq = 0.831
    n_gas = 9.889e-4
    temp_gas = 273.15

    T_gas = temp_gas/T_dim
    T = temp/T_dim

    if phase == 's':
        volume = num_par/n_sol
    elif phase == 'l':
        volume = num_par/n_liq
    elif phase == 'g':
        n = n_gas* T_gas/ T
        volume = num_par/n
    else:
        raise ValueError('phase not/incorrect defined. Acceptable values are string values {s, l, g}')

    box_size = volume**(1/3)
    unit_cells_1D = (num_par/ 4)**(1/3)
    alpha = box_size/ unit_cells_1D
    "Small constant is added to insure that closest_image works"
    L = box_size + 0.1

    return L, alpha


def init_fcc(
        L: float,
        alph: float,
        offset: np.ndarray,
        temp: float
            ) -> Tuple[np.ndarray, np.ndarray]:
    """Function fills a cube with sides of length L with FCC unit cells at a temperature temp.
    Function only places full FCC unit cells to fully fill a box and simulate a
    crystal lattice it is advised to choose L as an integer multiple of alph plus a small number.

    Parameters
    ----------
    L : float
        Box size
    alph : float
        Spacing between two unit cells
    offset : np.ndarray
        Vector added to every lattice position to shift the complete lattice
    temp : float
        Temperature of the lattice

    Returns
    -------
    Tuple[np.ndarray,np.ndarray]
        first array is the positions of every atom and the second the velocities
    """

    vec_basis_zer = alph*np.asarray([0, 0, 0]) #a0
    vec_basis_one = alph*np.asarray([0.5,0.5,0]) #a1
    vec_basis_two = alph*np.asarray([0,0.5,0.5]) #a2
    vec_basis_thr = alph*np.asarray([0.5,0,0.5]) #a3

    unit_cell = np.c_[
        vec_basis_zer,
        vec_basis_one,
        vec_basis_two,
        vec_basis_thr].T

    intervals = int(L/alph)
    x_int = np.arange(intervals) * alph
    y_int = x_int
    z_int = x_int

    X, Y, Z = np.meshgrid(x_int, y_int, z_int)
    rel_origin_coords = np.c_[X.flatten(),Y.flatten(),Z.flatten()]
    fcc_coords_base = np.tile(rel_origin_coords, (4,1,1))

    fcc_lattice_tiled = fcc_coords_base + unit_cell[:,np.newaxis,:]

    fcc_lattice = np.vstack((
        fcc_lattice_tiled[0],
        fcc_lattice_tiled[1],
        fcc_lattice_tiled[2],
        fcc_lattice_tiled[3]
        )) + offset

    num_parts = fcc_lattice.shape[0]
    lattice_velocities = init_v_gauss(num_particles=num_parts, temperature=temp)


    return fcc_lattice, lattice_velocities


def scaling_fac(velocity: np.ndarray, temperature: float,num_particles: int):
    """Fuction to determine the scaling factor for the velocities of the individual
    particles to adjust the temperature.

    Parameters
    ----------
    velocity : np.ndarray
        Matrix of the velocity elements of the individual particles with the element
        (i,j) the velocity of particle i in dimension j.
    temperature : float
        The intended temperature of the system
    num_particles : int
        The number of particles in the system

    Return
    ------
    scale_fac : float
        Scaling factor to adjust the velocities of the individual particles
    """

    #Converting the temperature into dimensionless variable
    T_dim = temperature/ETA_OVER_BOLTZMAN

    #summing the modulus of velocity vectors of the individual particles
    sum_v = np.sum(velocity ** 2)

    #scaling factor
    scale_fac = np.sqrt((num_particles-1)*3*T_dim/sum_v)

    return scale_fac


def system_temperature(velocities: np.ndarray) -> np.ndarray:
    """Calculates the temperature of the system in Kelvin, either at a single
    or over the whole trace

    Parameters
    ----------
    velocities : np.ndarray
        Array of the velocities of the particles in the system.

    Returns
    -------
    np.ndarray
        0 dimensional or 1 dimensional array for
        single timepoint or trace respectively

    Raises
    ------
    ValueError
        if velocities not of form (time point, particle, dimension) or (particle, dimension)
    """

    shape = velocities.shape

    if len(shape) == 3:
        form: str = "trace"
        (tsteps, N, dims) = shape
    elif len(shape) == 2:
        form: str = "point"
        (N, dims) = shape
    else:
        raise ValueError("Arraylike velocities not of form (time point, particle, dimension) or (particle, dimension)")

    if form == "trace":
        ek = np.sum(velocities**2, axis=(2,1))
        temp = 2/3*ek /(N-1) * ETA_OVER_BOLTZMAN /2
    elif form == "point":
        ek = np.sum(velocities**2, axis=(1,0))
        temp = ek /(N-1) * ETA_OVER_BOLTZMAN /2

    return temp


def equalise_system(
    r0: np.ndarray,
    v0: np.ndarray,
    desired_temperature: float,
    system_size: float,
    grace_time: int=50,
    error: float=5.0,
    timespacing: float=1e-3,
    adaptive=False
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Equalises the system of particles to a desired temperature defined in Kelvin
    by scaling all velocities of the particles by the same scaling fector.

    Parameters
    ----------
    r0 : np.ndarray
        the initial positions of the particles in the system to be equalised
    v0 : np.ndarray
        the initial velocities of the particles in the system to be equalised
    desired_temperature : float
        temperature to which the system is scaled in Kelvin.
    system_size : float
        size of the simulation space assumes and is restricted to a cube
        with sides of equal length
    grace_time : int, optional
        timesteps to let simulation run between subsequent rescalings, by default 50
    error : float, optional
        error in in temperature over the last 10 timesteps allowed to stop equalising, by default 5.0
    timespacing : float, optional
        integration time of Verlet integration method, ignored if adaptive is set to True, by default 1e-3
    adaptive : bool, optional
        lets the function use appropriate timespacings for the current particle velocities.
        Might fail at extremely high temperature, by default False

    Returns
    -------
    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]
        Array of positions, velocities and potentials over time. starting positions and velocities
        that meet the desired temperature.
    """

    (num, dim) = r0.shape
    L = system_size

    timespacing_opt = [1e-3, 1e-4, 1e-5]

    R, V = gen_rv_matrices(dim, num, grace_time)
    R, V = store_rv(R, V, r0, v0, 0)

    Rt, Vt, trsh, pot = Verlet_integrate_images(num, R, V, 1, grace_time, 0, system_size, D=3, timespacing=timespacing)
    temp = system_temperature(Vt[-10:])
    """
    print(temp)
    """
    temp_average = np.average(temp)

    v0 = Vt[-1].copy()
    r0 = Rt[-1].copy()
    while np.abs(temp_average - desired_temperature) >= error:
        rescale = scaling_fac(v0, desired_temperature, num)
        """
        print('factor: ',rescale)
        """
        v0 *= rescale

        if adaptive == True:
            if rescale <= 1e-3:
                timespacing = timespacing_opt[2]
            elif 1e-3 <= rescale <= 1e-1:
                timespacing = timespacing_opt[1]
            else:
                timespacing = timespacing_opt[0]

        RN, VN = None, None

        RN, VN = gen_rv_matrices(dim, num, grace_time)
        RN, VN = store_rv(RN, VN, r0, v0, 0)
        RNt, VNt, trsh, pott = Verlet_integrate_images(num, RN, VN, 1, grace_time, 0, system_size, D=3, timespacing=timespacing)

        R = np.append(R, RNt, axis=0)
        V = np.append(V, VNt, axis=0)
        pot = np.append(pot, pott, axis=0)
        temp = system_temperature(VNt[-10:])
        temp_average = np.average(temp)
        """
        print("temp: ",temp_average)
        """
        v0 = VNt[-1].copy()
        r0 = RNt[-1].copy()

    return R, V, pot, r0, v0




"""
Functions to compute forces and energies
"""


def closest_images(r: np.ndarray, L: float) -> np.ndarray:
    """Function that finds closest image particles corresponding to any original particle by treating the problem as a
    series of 1D problems. For a thurough understanding look at 'images_closest_explanation.ipynb'.

    Parameters
    ----------
    r : np.ndarray
        array of particle positions for a single timestep
    L : float
        Box size

    Returns
    -------
    np.ndarray
        Lookup table of which image particles are closest to any given particle.
        An D X N X N matrix (with D representing number of dimensions and N the number of particles

        Intrepetation:
        Element (i,j,k) represents the location of particle k closest to particle j for dimension i

    Note
    ----
    Maybe include potential energy calculation in this function, as it already calculates the
    minimum distance between the particles
    """

    part_amnt, dims = r.shape
    nax = np.newaxis #don't complain

    lookup_arr = np.zeros((dims, part_amnt, part_amnt))

    for dim in range(dims):

        dim_coord = r[:,dim]
        dim_minor_im = dim_coord - L
        dim_major_im = dim_coord + L

        poss_dimj = np.column_stack((dim_minor_im,
                                    dim_coord,
                                    dim_major_im
                                    )
        )

        poss_dimj_tiled = np.tile(poss_dimj, (part_amnt, 1, 1))
        poss_dimj_tiled_diff = poss_dimj_tiled - dim_coord[:, nax, nax]
        dimj_dist = poss_dimj_tiled_diff**2
        min_dist = np.min(dimj_dist, axis=2)

        mask = np.equal(dimj_dist, min_dist[:,:,nax])
        dimj_closest_dimi = poss_dimj_tiled[mask].reshape((part_amnt,part_amnt))

        lookup_arr[dim, :, :] = dimj_closest_dimi

    return lookup_arr




def compute_force(part_one_pos: np.ndarray,
                  part_two_pos: np.ndarray) -> np.ndarray:
    """Function that computes the force between two particles abiding
    a Lennart-Jones potential and returns its magnitude in the x- and y-direction

    Parameters
    ----------
    part_one_pos : np.ndarray
        numpy array containing the coordinates of the first particle
    part_two_pos : np.ndarray
        numpy array containing the coordinates of the second particle

    Returns
    -------
    Tuple[float, float]
        numpy array of the force on particle two due to particle one in the x-
        and y-direction
    """
    #distances are calculated from particle one to particle two:
    distance_vector = part_two_pos - part_one_pos
    dist_magn   = np.sqrt(np.sum(distance_vector**2))

    r       = dist_magn
    prefctr = 24/(r**2)*((1/r)**6 -2*(1/r)**12)
    force = 1*distance_vector*prefctr

    return force


def get_forces(N: int, r: np.ndarray, tstep: int, D=2) -> np.ndarray:
    """Computes an array of size N by D with the forces in x- and y-direction

    Parameters
    ----------
    N : int
        Number of particles
    r : np.ndarray
        Array of positions of particle
    tstep : int
        Previous time step
    D : int, optional
        Dimensionality of problem, by default 2

    Returns
    -------
    np.ndarray
        Array of forces
    """
    array_forces = np.zeros((N,D))

    for particle_one in range(N-1):
        for particle_two in range(particle_one+1, N-1):
            part_one_pos = r[tstep, particle_one, :]
            part_two_pos = r[tstep, particle_two, :]

            force_one = compute_force(part_one_pos, part_two_pos)
            array_forces[particle_one, :] = force_one[:]
            array_forces[particle_two, :] = -force_one[:]

    return array_forces

def image_forces(lookup_arr: np.ndarray) -> np.ndarray:
    """
    Function to calculate the net force on each particle

    Parameters
    ----------
    lookup_arr : np.ndarray
        array of location of closest particles
        intepretation:
            Element (i,j,k) represents location of particle k closest to particle j in dimension i

    Return
    ------
    array_forces : np.ndarray
        net force on each particle
        intepratation:
            Element (i,j) represents the net force on particle i of dimension j
    """
    (dims, part_amnt, tmp) = lookup_arr.shape

    array_forces = np.zeros((part_amnt, dims))

    for parti in range(part_amnt):
        icoords = lookup_arr[:,parti,parti]
        for partj in range(part_amnt):
            if partj != parti:
                jcoords = lookup_arr[:,parti,partj]
                array_forces[parti] = array_forces[parti] + compute_force(icoords, jcoords)

    return array_forces

def particle_E_kin(velocity: np.ndarray) -> np.ndarray:
    """
    Function intendend to calculate the kinetic energy of the individual
    particles.

    Parameters
    ----------
    velocity : np.ndarray
        A 2D matrix containing the the velocity vectors of the individual
        particles at one time step
        Interpretation:
            Element (i,j) represents the velocity in the j dimension of particle i

    Return
    ------
    E_kin : np.ndarray
        The calculated kinetic energy of the individual particles
        Interpratation:
            Element (i) represents the kinetic energy of particle i
    """

    #determining the number of spacial dimentions the particles exist in and
    #the number of particles in the system
    tmsp, num_particles, space_dim = np.shape(velocity)
    E_kin = (velocity ** 2) @ np.ones((space_dim, 1)) / 2

    return E_kin


def two_particle_E_pot(part_1_position: np.ndarray,
                       part_2_position: np.ndarray) -> np.ndarray:
    """
    Function to calculate the potential energy of two particles.

    Parameters
    ----------
    part_1_position : np.ndarray
        Position vector of particle 1
    part_2_position : np.ndarray
        Position vector of particle 2

    Return
    ------
    E_pot : np.ndarray
        Potential enegies of the two particles
    """

    #distance vector between the two particles and the modulus of the
    #distance vector
    dis_vector = part_1_position - part_2_position
    dis_magnitude = np.sqrt(dis_vector @ dis_vector)

    #The first equation for E_pot does not use dimentionless units, the
    #second does
    #E_pot = 4*ETA((SIGMA/dis_magnitude) ** 12 - (SIGMA/dis_magnitude) ** 6)
    E_pot = 4*((dis_magnitude) ** -12 - (dis_magnitude) ** -6)

    return E_pot


def image_potential(lookup_arr: np.ndarray) -> np.ndarray:
    """determines the potential energy of every particle using the method of
    closest images.

    Parameters
    ----------
    lookup_arr : np.ndarray
        array containing every particles closest image

    Returns
    -------
    np.ndarray
        potentials of particles
    """

    (dims, part_amnt, tmp) = lookup_arr.shape

    E_potential = np.zeros(part_amnt)

    for parti in range(part_amnt):
        icoords = lookup_arr[:,parti,parti]
        for partj in range(part_amnt):
            if partj != parti:
                jcoords = lookup_arr[:,parti,partj]
                E_potential[parti] = E_potential[parti] + two_particle_E_pot(icoords,jcoords)

    return E_potential


@njit
def compute_force_potential(part_one_pos: np.ndarray,
                  part_two_pos: np.ndarray) -> Tuple[np.ndarray,np.ndarray]:
    """Function that computes the force between two particles abiding
    a Lennart-Jones potential and returns its magnitude in the x- and y-direction

    Parameters
    ----------
    part_one_pos : np.ndarray
        numpy array containing the coordinates of the first particle
    part_two_pos : np.ndarray
        numpy array containing the coordinates of the second particle

    Returns
    -------
    Tuple[float, float]
        numpy array of the force on particle two due to particle one in the x-
        and y-direction
    """
    #distances are calculated from particle one to particle two:
    distance_vector = part_two_pos - part_one_pos
    dist_magn   = np.sqrt(np.sum(distance_vector**2))

    r       = dist_magn
    prefctr = 24/(r**2)*((1/r)**6 -2*(1/r)**12)
    force = 1*distance_vector*prefctr
    E_pot = 4*((r) ** -12 - (r) ** -6)

    if np.any(np.isnan(force)):
        raise RuntimeError("force between particles is nan.")


    return force, E_pot


@njit
def image_forces_potentials(lookup_arr: np.ndarray) -> np.ndarray:
    """
    Function to calculate the net force on each particle

    Parameters
    ----------
    lookup_arr : np.ndarray
        array of location of closest particles
        intepretation:
            Element (i,j,k) represents location of particle k closest to particle j in dimension i

    Return
    ------
    array_forces : np.ndarray
        net force on each particle
        intepratation:
            Element (i,j) represents the net force on particle i of dimension j
    """
    (dims, part_amnt, tmp) = lookup_arr.shape

    array_forces = np.zeros((part_amnt, dims))
    array_potentials = np.zeros(part_amnt)

    for parti in range(part_amnt):
        icoords = lookup_arr[:,parti,parti]
        for partj in range(parti+1, part_amnt):
            jcoords = lookup_arr[:,parti,partj]
            force, pot = compute_force_potential(icoords, jcoords)
            array_forces[parti] += force
            array_forces[partj] -= force
            array_potentials[parti] += pot
            #array_potentials[partj] += pot

    return array_forces, array_potentials

"""
Functions to inegrate over time steps
"""

def Euler_integrate(N: int, r: np.ndarray, v:np.ndarray, m: float, h: int, Tend: float, L: float, D=2) -> np.ndarray:
    """Computes two arrays of size h by N by D with the positions and velocities in x- and y-direction at each   time step

    Parameters
    ----------
    N : int
        Number of particles
    r : np.ndarray
        Array of initial positions of particles
    v : np.ndarray
        Array of initial velocities of particles
    h : int
        Number of time steps
    m : float
        Mass of the particle
    Tend : float
        End time of the simulation
    L : float
        Side length of the square box
    D : int, optional
        Dimensionality of problem, by default 2

    Returns
    -------
    2 np.ndarray
        Array of postions and array of velocities
    """
    timespacing = Tend/(h-1)
    for timestep in range(h-1):
        v[timestep+1,:,:] = v[timestep,:,:] + timespacing*get_forces(N,r,timestep,D)
        r[timestep+1,:,:] = r[timestep,:,:] + timespacing*v[timestep,:,:]
        "Implement periodic boundary conditions"
        r = r - L*np.floor(r/L)

    return (r,v)


def Euler_integrate_images(N: int, r: np.ndarray,
                        v:np.ndarray, m: float, h: int,
                        Tend: float, L: float, D=2) -> np.ndarray:
    """Computes two arrays of size h by N by D with the positions and velocities in x- and y-direction at each   time step

    Parameters
    ----------
    N : int
        Number of particles
    r : np.ndarray
        Array of initial positions of particles
    v : np.ndarray
        Array of initial velocities of particles
    h : int
        Number of time steps
    m : float
        Mass of the particle
    Tend : float
        End time of the simulation
    L : float
        Side length of the square box
    D : int, optional
        Dimensionality of problem, by default 2

    Returns
    -------
    2 np.ndarray
        Array of postions and array of velocities
    """
    timespacing = 1e-2
    forces = np.zeros((h,N,D))
    potentials = np.zeros((h,N))

    for t in range(h-1):
        lookup_arr = closest_images(r[t], L)
        force, potential = image_forces_potentials(lookup_arr)
        forces[t,:,:] = force
        potentials[t,:] = potential
        r[t+1,:,:] = r[t,:,:] + timespacing*v[t,:,:]
        v[t+1,:,:] = v[t,:,:] + timespacing*force
        "Implement periodic boundary conditions"
        r = r - L*np.floor(r/L)

    return (r,v,forces,potentials)

def Verlet_integrate_images(N: int, r: np.ndarray,
                        v:np.ndarray, m: float, h: int,
                        Tend: float, L: float, D=3,
                        timespacing: float=1e-2) -> np.ndarray:
    """Computes two arrays of size h by N by D with the positions and velocities in x- and y-direction at each   time step

    Parameters
    ----------
    N : int
        Number of particles
    r : np.ndarray
        Array of initial positions of particles
    v : np.ndarray
        Array of initial velocities of particles
    h : int
        Number of time steps
    m : float
        Mass of the particle
    Tend : float
        End time of the simulation
    L : float
        Side length of the square box
    D : int, optional
        Dimensionality of problem, by default 2

    Returns
    -------
    2 np.ndarray
        Array of postions and array of velocities
    """
    forces = np.zeros((h,N,D))
    potentials = np.zeros((h,N))
    lookup_arr = closest_images(r[0], L)
    force, potential = image_forces_potentials(lookup_arr)
    forces[0,:,:] = force
    potentials[0,:] = potential

    for t in range(h-1):
        r[t+1,:,:] = r[t,:,:] + timespacing*v[t,:,:] + 0.5*timespacing**2*forces[t,:,:]
        lookup_arr = closest_images(r[t+1], L)
        force, potential = image_forces_potentials(lookup_arr)
        forces[t+1,:,:] = force
        potentials[t+1, :] = potential
        v[t+1,:,:] = v[t,:,:] + 0.5*timespacing*(forces[t+1,:,:] + forces[t,:,:])
        "Implement periodic boundary conditions"
        r = r - L*np.floor(r/L)
        #print(t) #debugging only

    return (r,v,forces,potentials)


def all_poss_combs(opts: list, positions: int) -> Tuple[list, ...]:
    """Function that returns a list with all combinations of the options in opts
    in positions

    Parameters
    ----------
    opts : list
        list of options, for example [0, 1] for combinations using only o and 1
    positions : int
        number of positions on which to place an entry of list, for example 2

    Returns
    -------
    Tuple[list, ...]
        list containg lists of individual combinations for example [[0,0],[0,1],[1,0], [1,1]]
    """

    if positions == 1:
        extr_combs = []
        for opt in opts:
            extr_combs.append(opt)
        return extr_combs
    if positions != 1:
        curr_combs = []
        extr_combs = all_poss_combs(opts, positions-1)
        for opt in opts:
            for j in range(len(extr_combs)):
                curr_combs.append([opt])
        for i in range(len(curr_combs)):
            combd_add = extr_combs[i % len(extr_combs)]
            if type(combd_add) != int:
                for x in combd_add:
                    curr_combs[i].append(x)
            else:
                curr_combs[i].append(combd_add)
        return curr_combs
    return curr_combs

"""
Functions to compute observables and errors
"""
def pair_correlation(r: np.ndarray, Nbins: int, L: float) -> Tuple[np.ndarray,np.array]:
    """Function to determine the pair correlation histogram averaged over all timesteps

    Parameters
    ----------
    r : np.ndarray
        Matrix of the particles positions at each timestep
    Nbins : int
        Number of histogram bins
    L : float
        Box size

    Return
    ------
    g : np.array
        autocorrelation function averaged over all timesteps
    bins : np.array
        array containing the bin edges of the autocorrelation histogram
    """


    V = L**3

    shape = r.shape
    if len(shape) == 3:
        form: str = "trace"
        (tsteps, N, dims) = shape
    elif len(shape) == 2:
        form: str = "point"
        (N, dims) = shape
        tsteps = 1

    binsize = (L-0.5)/Nbins
    normconst = 4*V/(N*(N-1)/(4*np.pi*binsize))
    "put 4 here instead of 2 to avoid having to loop over all pairs"
    bins = np.arange(0.5,L, binsize)
    hist = np.zeros(Nbins-1)

    if form == "trace":
        for t in range(tsteps):
            lookup = closest_images(r[t], L)
            distances = np.zeros(N*N)
            for parti in range(N):
                icoords = lookup[:,parti,parti]
                for partj in range(parti+1,N):
                    jcoords = lookup[:,parti,partj]
                    dist = np.sqrt(np.sum((icoords-jcoords)**2))
                    distances[parti*N+partj] = dist

            distances = distances[distances!=0]
            histo, bins = np.histogram(distances, bins)
            hist += histo
    elif form == "point":
        lookup = closest_images(r, L)
        distances = np.zeros(N*N)
        for parti in range(N):
            icoords = lookup[:,parti,parti]
            for partj in range(parti+1,N):
                jcoords = lookup[:,parti,partj]
                dist = np.sqrt(np.sum((icoords-jcoords)**2))
                distances[parti*N+partj] = dist

        distances = distances[distances!=0]
        histo, bins = np.histogram(distances, bins)
        hist += histo

    bins = np.delete(bins,0)
    g = normconst*np.divide(hist,bins**2)/tsteps

    return g , bins


def MeanSquaredDisplacement(v, forces, timespacing) -> np.array:
    """Function to determine the MSD as a function of time

    Parameters
    ----------
    v : np.array
        Array containing the velocities of each particle at each timestep
    forces : np.array
        Array containing the forces on each particle at each timestep
    timespacing : float
        timestep size used to simulated the data

    Return
    ------
    MSD : np.array
        Array of the MSD as a function of time
    """
    h, N, dim = v.shape
    displacement = timespacing*v+0.5*timespacing**2*forces
    cum_displacement = np.zeros(displacement.shape)
    for t in range(h):
        cum_displacement[t,:,:] = np.sum(displacement[:t,:,:],0)
    MSD = 1/N*np.sum(np.sum(cum_displacement**2,2),1)
    return MSD

def finite_autocorr(data) -> np.array:
    """Function to determine the finite autocorrelation data of a given data set

    Parameters
    ----------
    data : np.array
        Array containing the data

    Return
    ------
    chi : np.array
        Array of the autocorrelation as a function of time
    """

    N = data.size
    chi = np.zeros(N-1)

    for t in range(N-1):
        num = (N-t)*np.dot(data[:N-t],data[t-N:])-np.sum(data[:N-t])*np.sum(data[t-N:])
        denom = np.sqrt((N-t)*np.sum(data[:N-t]**2)-np.sum(data[:N-t])**2)*np.sqrt((N-t)*np.sum(data[t-N:]**2)-np.sum(data[t-N:])**2)
        chi[t] = num/denom

    return chi

def error(data, tau) -> float:
    """Function to determine the finite autocorrelation data of a given data set

    Parameters
    ----------
    data : np.array
        Array containing the data
    tau : float
        Correlation time of the data

    Return
    ------
    sigma : np.array
        standard deviation of the data
    """

    N = data.size
    sigma = np.sqrt(2*tau/N*(1/N*np.sum(data**2)-(1/N*np.sum(data))**2))
    return sigma




